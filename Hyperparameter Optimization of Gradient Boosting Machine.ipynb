{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Hyperparameter Optimization\n",
    "\n",
    "In this notebook we will explore several options for hyperparameter optimization of a machine learning algorithm. We will start with some of the basic methods such as random search, and then proceed to more sophisticated methods using Guassian Processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (5822, 85)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>ALEVEN</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  MGODOV  \\\n",
       "0       33         1        3         2         8       0       5       1   \n",
       "1       37         1        2         2         8       1       4       1   \n",
       "2       37         1        2         2         8       0       4       2   \n",
       "3        9         1        3         3         3       2       3       2   \n",
       "4       40         1        4         2        10       1       4       1   \n",
       "\n",
       "   MGODGE  MRELGE    ...     ALEVEN  APERSONG  AGEZONG  AWAOREG  ABRAND  \\\n",
       "0       3       7    ...          0         0        0        0       1   \n",
       "1       4       6    ...          0         0        0        0       1   \n",
       "2       4       3    ...          0         0        0        0       1   \n",
       "3       4       5    ...          0         0        0        0       1   \n",
       "4       4       7    ...          0         0        0        0       1   \n",
       "\n",
       "   AZEILPL  APLEZIER  AFIETS  AINBOED  ABYSTAND  \n",
       "0        0         0       0        0         0  \n",
       "1        0         0       0        0         0  \n",
       "2        0         0       0        0         0  \n",
       "3        0         0       0        0         0  \n",
       "4        0         0       0        0         0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data and separate into training and testing sets\n",
    "data = pd.read_csv('data/caravan-insurance-challenge.csv')\n",
    "train = data[data['ORIGIN'] == 'train']\n",
    "test = data[data['ORIGIN'] == 'test']\n",
    "\n",
    "# Extract the labels and format properly\n",
    "train_labels = np.array(train['CARAVAN'].astype(np.int32)).reshape((-1,))\n",
    "test_labels = np.array(test['CARAVAN'].astype(np.int32)).reshape((-1,))\n",
    "\n",
    "# Drop the unneeded columns\n",
    "train = train.drop(columns = ['ORIGIN', 'CARAVAN'])\n",
    "test = test.drop(columns = ['ORIGIN', 'CARAVAN'])\n",
    "\n",
    "# Convert to numpy array for splitting in cross validation\n",
    "features = np.array(train)\n",
    "labels = train_labels\n",
    "\n",
    "print('Train shape: ', train.shape)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search by Hand\n",
    "\n",
    "The first method we can implement is simply random search. Each iteration, choose a random set of model hyperparameters from a search space. Empirically, random search is very effective, returning nearly as good results as grid search with a significant reduction in time spent searching. \n",
    "\n",
    "Random search can be implement in the Scikit-Learn library with the LightGBM Sklearn API. However, this does not support training with early stopping, which is the most effective method for determining the best number of iterations to use. Therefore, we will implement random search ourselves with a defined parameter grid, and using Early Stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain \n",
    "\n",
    "In random search, as in Bayesian optimization, we have a domain over which we search for the best hyperparameters. In terms of a random or grid search, this is generally known as a hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(30, 151)),\n",
    "    'learning_rate': list(np.logspace(np.log(0.01), np.log(0.2), base = np.exp(1), num = 100)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.6, 1, 10))\n",
    "}\n",
    "\n",
    "# Subsampling (only applicable with 'goss')\n",
    "subsample_dist = list(np.linspace(0.5, 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = 50\n",
    "\n",
    "# Dataframe to hold cv results\n",
    "results = pd.DataFrame(columns = ['params', 'train_scores', 'train', 'valid_scores', 'valid', 'estimators'],\n",
    "                       index = list(range(evals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# Iterate through the specified number of evaluations\n",
    "for i in range(evals):\n",
    "    \n",
    "    k_fold = KFold(n_splits = 5)\n",
    "    \n",
    "    # Randomly sample parameters for gbm\n",
    "    params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n",
    "    \n",
    "    \n",
    "    if params['boosting_type'] == 'goss':\n",
    "        # Cannot subsample with goss\n",
    "        params['subsample'] = 1.0\n",
    "    else:\n",
    "        # Subsample supported for gdbt and dart\n",
    "        params['subsample'] = random.sample(subsample_dist, 1)[0]\n",
    "        \n",
    "        \n",
    "    # Create the model with the parameters\n",
    "    model = lgb.LGBMClassifier(class_weight = params['class_weight'], boosting_type = params['boosting_type'], \n",
    "                               num_leaves = params['num_leaves'], learning_rate = params['learning_rate'], \n",
    "                               subsample_for_bin = params['subsample_for_bin'], min_child_samples = params['min_child_samples'], \n",
    "                               reg_alpha = params['reg_alpha'], reg_lambda = params['reg_lambda'], \n",
    "                               colsample_by_tree = params['colsample_bytree'], subsample = params['subsample'], \n",
    "                               n_estimators = 10000, n_jobs = -1, objective = 'binary', verbose=-1, verbose_eval = False)\n",
    "    \n",
    "    # Empty lists for records\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    number_estimators = []\n",
    "    \n",
    "    # Split the data\n",
    "    for (train_indices, valid_indices) in k_fold.split(features):\n",
    "        \n",
    "        # Training data and validation set\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Fit the model using early stopping\n",
    "        model.fit(train_features, train_labels, eval_set = [(train_features, train_labels), (valid_features, valid_labels)],\n",
    "                  eval_metric = 'auc', eval_names = ['train', 'valid'], early_stopping_rounds = 200, verbose = -1);\n",
    "        \n",
    "        \n",
    "        valid_scores.append(model.best_score_['valid']['auc'])\n",
    "        train_scores.append(model.best_score_['train']['auc'])\n",
    "        number_estimators.append(model.best_iteration_)\n",
    "        \n",
    "    # Average the scores\n",
    "    valid = np.mean(valid_scores)\n",
    "    train = np.mean(train_scores)\n",
    "    estimators = np.mean(number_estimators)\n",
    "    \n",
    "    # Add results to next row in dataframe\n",
    "    results.loc[i, :] = [params, train_scores, train, valid_scores, valid, estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>train_scores</th>\n",
       "      <th>train</th>\n",
       "      <th>valid_scores</th>\n",
       "      <th>valid</th>\n",
       "      <th>estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'class_weight': 'balanced', 'boosting_type': ...</td>\n",
       "      <td>[0.7933412575717002, 0.8286344299191658, 0.802...</td>\n",
       "      <td>0.811818</td>\n",
       "      <td>[0.78293542074364, 0.7701678321678321, 0.76352...</td>\n",
       "      <td>0.774208</td>\n",
       "      <td>194.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'class_weight': None, 'boosting_type': 'dart'...</td>\n",
       "      <td>[0.8257757347444721, 0.8347006322293152, 0.838...</td>\n",
       "      <td>0.842635</td>\n",
       "      <td>[0.7742922374429224, 0.7666013986013986, 0.764...</td>\n",
       "      <td>0.771655</td>\n",
       "      <td>154.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'class_weight': 'balanced', 'boosting_type': ...</td>\n",
       "      <td>[0.8622850064319405, 0.8727789976426716, 0.895...</td>\n",
       "      <td>0.864722</td>\n",
       "      <td>[0.7871428571428571, 0.7512867132867133, 0.758...</td>\n",
       "      <td>0.771515</td>\n",
       "      <td>88.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'class_weight': 'balanced', 'boosting_type': ...</td>\n",
       "      <td>[0.8193216150988777, 0.8624153971185337, 0.818...</td>\n",
       "      <td>0.82953</td>\n",
       "      <td>[0.7800521852576647, 0.7546853146853146, 0.759...</td>\n",
       "      <td>0.771392</td>\n",
       "      <td>201.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'class_weight': 'balanced', 'boosting_type': ...</td>\n",
       "      <td>[0.7931983255596938, 0.8368935615369328, 0.816...</td>\n",
       "      <td>0.824112</td>\n",
       "      <td>[0.7805544683626875, 0.7537902097902098, 0.766...</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>163.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  \\\n",
       "11  {'class_weight': 'balanced', 'boosting_type': ...   \n",
       "0   {'class_weight': None, 'boosting_type': 'dart'...   \n",
       "25  {'class_weight': 'balanced', 'boosting_type': ...   \n",
       "23  {'class_weight': 'balanced', 'boosting_type': ...   \n",
       "6   {'class_weight': 'balanced', 'boosting_type': ...   \n",
       "\n",
       "                                         train_scores     train  \\\n",
       "11  [0.7933412575717002, 0.8286344299191658, 0.802...  0.811818   \n",
       "0   [0.8257757347444721, 0.8347006322293152, 0.838...  0.842635   \n",
       "25  [0.8622850064319405, 0.8727789976426716, 0.895...  0.864722   \n",
       "23  [0.8193216150988777, 0.8624153971185337, 0.818...   0.82953   \n",
       "6   [0.7931983255596938, 0.8368935615369328, 0.816...  0.824112   \n",
       "\n",
       "                                         valid_scores     valid estimators  \n",
       "11  [0.78293542074364, 0.7701678321678321, 0.76352...  0.774208      194.6  \n",
       "0   [0.7742922374429224, 0.7666013986013986, 0.764...  0.771655      154.4  \n",
       "25  [0.7871428571428571, 0.7512867132867133, 0.758...  0.771515       88.6  \n",
       "23  [0.7800521852576647, 0.7546853146853146, 0.759...  0.771392      201.4  \n",
       "6   [0.7805544683626875, 0.7537902097902098, 0.766...  0.770769      163.4  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results.sort_values('valid', ascending = False)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 0.8222222222222222,\n",
       " 'learning_rate': 0.08834940584779544,\n",
       " 'min_child_samples': 415,\n",
       " 'num_leaves': 36,\n",
       " 'reg_alpha': 0.36734693877551017,\n",
       " 'reg_lambda': 0.42857142857142855,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 220000}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Hyperparameter Optimization using Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from hyperopt.pyll.stochastic import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28d948ca278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2))}\n",
    "learning_rate_dist = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n",
    "    \n",
    "plt.hist(learning_rate_dist, bins = 10, edgecolor = 'k');\n",
    "plt.title('Learning Rate Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28d948cac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_leaves = {'num_leaves': hp.quniform('num_leaves', 30, 150, 1)}\n",
    "num_leaves_dist = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    num_leaves_dist.append(sample(num_leaves)['num_leaves'])\n",
    "    \n",
    "plt.hist(num_leaves_dist, bins = 10, edgecolor = 'k');\n",
    "plt.title('Number of Leaves Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Function\n",
    "\n",
    "The objective function will be the cross validation score evaluate over 5 folds. We need to make sure the objective function returns a single, real-value metric. We can return more information in the form of a dictionary where one of the keys must be 'loss' and another must be 'STATUS'. The other keys can hold information such as the hyperparameters used or the evaluation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \n",
    "    global iteration\n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "    k_fold = KFold(n_splits = 5)\n",
    "    \n",
    "    # Retrieve the subsample if present otherwise set to 1.0\n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type\n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    \n",
    "    \n",
    "    model = lgb.LGBMClassifier(n_estimators = 10000, **params, objective = 'binary', n_jobs = -1, verbose = -1)\n",
    "    \n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    number_estimators = []\n",
    "    \n",
    "    start = timer()\n",
    "    for (train_indices, valid_indices) in k_fold.split(features):\n",
    "        \n",
    "        # Training data and validation set\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Fit the model using early stopping\n",
    "        model.fit(train_features, train_labels, eval_set = [(train_features, train_labels), (valid_features, valid_labels)],\n",
    "                  eval_metric = 'auc', eval_names = ['train', 'valid'], early_stopping_rounds = 200, verbose = -1)\n",
    "    \n",
    "        valid_scores.append(model.best_score_['valid']['auc'])\n",
    "        train_scores.append(model.best_score_['train']['auc'])\n",
    "        number_estimators.append(model.best_iteration_)\n",
    "        \n",
    "    end = timer()\n",
    "    \n",
    "    run_time = end - start\n",
    "    \n",
    "    # fmin needs a loss to minimize\n",
    "    valid = -1 * np.mean(valid_scores)\n",
    "    train = -1 * np.mean(train_scores)\n",
    "    \n",
    "    # average number of estimators\n",
    "    estimators = np.mean(number_estimators)\n",
    "\n",
    "    o_f = open(out_file, 'a')\n",
    "    writer = csv.writer(o_f)\n",
    "    \n",
    "    writer.writerow([valid, train, estimators, run_time, params, iteration])\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': valid, 'train': train, 'estimators': estimators, \n",
    "            'train_time': run_time, 'status': STATUS_OK, 'params': params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss'}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_type = {'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss'}])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': {'boosting_type': 'gbdt', 'subsample': 0.7740352912413226}}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(boosting_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': {'boosting_type': 'gbdt', 'subsample': 0.5650619799468094}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(boosting_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.07332503469774355}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01458107577805972}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Sampling from the space\n",
    "\n",
    "After finding the boosting type (which is in a nested dictionary), we assign the boosting type to make it a top level value. We use the dictionary get method to find the 'subsample' if it is in the dictionary (indicating the boosting type is 'gbdt' or 'dart') or set it to 1.0 otherwise (if boosting type is 'goss'). The goss boosting type cannot use bagging. \n",
    "\n",
    "This entire step is necessary because of the conditional logic used for the boosting type and subsample ratio.\n",
    "\n",
    "In addition, we can see the other variables in the dictionary. These will change every time we sample the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 0.6577229621326403,\n",
       " 'learning_rate': 0.09018593425044565,\n",
       " 'min_child_samples': 490.0,\n",
       " 'num_leaves': 62.0,\n",
       " 'reg_alpha': 0.9993481076517804,\n",
       " 'reg_lambda': 0.04709602531106005,\n",
       " 'subsample': 0.7426383081799275,\n",
       " 'subsample_for_bin': 260000.0}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 0.6786649460319185,\n",
       " 'learning_rate': 0.13609118387610378,\n",
       " 'min_child_samples': 170.0,\n",
       " 'num_leaves': 47.0,\n",
       " 'reg_alpha': 0.932334899589745,\n",
       " 'reg_lambda': 0.21663480544441094,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 300000.0}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "out_file = 'gbm_trials1.csv'\n",
    "iteration = 1\n",
    "\n",
    "o_f = open(out_file, 'w')\n",
    "writer = csv.writer(o_f)\n",
    "writer.writerow(['loss', 'train', 'estimators', 'train_time', 'params', 'iteration'])\n",
    "o_f.close()\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 5, trials = trials, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_results = sorted(trials.results, key = lambda x: x['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estimators': 27.6,\n",
       "  'loss': -0.7680556486219079,\n",
       "  'params': {'boosting_type': 'goss',\n",
       "   'class_weight': None,\n",
       "   'colsample_bytree': 0.7091166398604745,\n",
       "   'learning_rate': 0.1422994267383496,\n",
       "   'min_child_samples': 105,\n",
       "   'num_leaves': 72,\n",
       "   'reg_alpha': 0.5373808334224935,\n",
       "   'reg_lambda': 0.6324246210393318,\n",
       "   'subsample': 1.0,\n",
       "   'subsample_for_bin': 280000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.8192922265006158,\n",
       "  'train_time': 1.4967931760697866},\n",
       " {'estimators': 120.0,\n",
       "  'loss': -0.767192231335177,\n",
       "  'params': {'boosting_type': 'dart',\n",
       "   'class_weight': 'balanced',\n",
       "   'colsample_bytree': 0.9764218640046081,\n",
       "   'learning_rate': 0.02598662929835806,\n",
       "   'min_child_samples': 180,\n",
       "   'num_leaves': 36,\n",
       "   'reg_alpha': 0.913665951698357,\n",
       "   'reg_lambda': 0.5039045255448302,\n",
       "   'subsample': 0.5625144487644012,\n",
       "   'subsample_for_bin': 160000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.8248670929390949,\n",
       "  'train_time': 5.63601837281999}]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('trials.json', 'w') as f:\n",
    "    f.write(json.dumps(trials_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "out_file = 'gbm_trials2.csv'\n",
    "iteration = 1\n",
    "\n",
    "o_f = open(out_file, 'w')\n",
    "writer = csv.writer(o_f)\n",
    "writer.writerow(['loss', 'train', 'estimators', 'train_time', 'params', 'iteration'])\n",
    "o_f.close()\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 100, trials = trials, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estimators': 190.6,\n",
       "  'loss': -0.7759073075332217,\n",
       "  'params': {'boosting_type': 'goss',\n",
       "   'class_weight': 'balanced',\n",
       "   'colsample_bytree': 0.8330831850590065,\n",
       "   'learning_rate': 0.09810697588574817,\n",
       "   'min_child_samples': 345,\n",
       "   'num_leaves': 56,\n",
       "   'reg_alpha': 0.12050339751864594,\n",
       "   'reg_lambda': 0.6624785442544581,\n",
       "   'subsample': 1.0,\n",
       "   'subsample_for_bin': 40000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.8226633159100203,\n",
       "  'train_time': 1.8711530343939557},\n",
       " {'estimators': 96.6,\n",
       "  'loss': -0.7757987902380926,\n",
       "  'params': {'boosting_type': 'dart',\n",
       "   'class_weight': 'balanced',\n",
       "   'colsample_bytree': 0.6299729132064589,\n",
       "   'learning_rate': 0.08918255440712065,\n",
       "   'min_child_samples': 165,\n",
       "   'num_leaves': 49,\n",
       "   'reg_alpha': 0.36697068936519106,\n",
       "   'reg_lambda': 0.43413063904461346,\n",
       "   'subsample': 0.8144877881171244,\n",
       "   'subsample_for_bin': 80000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.874525436679552,\n",
       "  'train_time': 6.711731730433257}]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = sorted(trials.results, key = lambda x: x['loss'], reverse = False)\n",
    "results[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this notebook, we saw how to use Hyperopt and the Tree Parzen Estimator to optimize the hyperparameters of a gradient boosting machine. Bayesian model-based optimization is more efficient than random search, finding a better set of model hyperparameters in fewer objective function (train-predict-evaluate) calls. In later notebooks we will examine using hyperparameter optimization on additional problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
