{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Hyperparameter Optimization\n",
    "\n",
    "In this notebook we will explore several options for hyperparameter optimization of a machine learning algorithm. We will start with some of the basic methods such as random search, and then proceed to more sophisticated methods using Guassian Processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(objective = 'binary', n_jobs = -1, boosting_type='goss', colsample_bytree=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    5822\n",
       "test     4000\n",
       "Name: ORIGIN, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ORIGIN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>...</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>CARAVAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN  MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  \\\n",
       "0  train       33         1        3         2         8       0       5   \n",
       "1  train       37         1        2         2         8       1       4   \n",
       "2  train       37         1        2         2         8       0       4   \n",
       "3  train        9         1        3         3         3       2       3   \n",
       "4  train       40         1        4         2        10       1       4   \n",
       "\n",
       "   MGODOV  MGODGE   ...     APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  \\\n",
       "0       1       3   ...            0        0        0       1        0   \n",
       "1       1       4   ...            0        0        0       1        0   \n",
       "2       2       4   ...            0        0        0       1        0   \n",
       "3       2       4   ...            0        0        0       1        0   \n",
       "4       1       4   ...            0        0        0       1        0   \n",
       "\n",
       "   APLEZIER  AFIETS  AINBOED  ABYSTAND  CARAVAN  \n",
       "0         0       0        0         0        0  \n",
       "1         0       0        0         0        0  \n",
       "2         0       0        0         0        0  \n",
       "3         0       0        0         0        0  \n",
       "4         0       0        0         0        0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/caravan-insurance-challenge.csv')\n",
    "train = data[data['ORIGIN'] == 'train']\n",
    "test = data[data['ORIGIN'] == 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search by Hand\n",
    "\n",
    "The first method we can implement is simply random search. Each iteration, choose a random set of model hyperparameters from a search space. Empirically, random search is very effective, returning nearly as good results as grid search with a significant reduction in time spent searching. \n",
    "\n",
    "Random search can be implement in the Scikit-Learn library with the LightGBM Sklearn API. However, this does not support training with early stopping, which is the most effective method for determining the best number of iterations to use. Therefore, we will implement random search ourselves with a defined parameter grid, and using Early Stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train['CARAVAN'].astype(np.int32)).reshape((-1,))\n",
    "test_labels = np.array(test['CARAVAN'].astype(np.int32)).reshape((-1,))\n",
    "\n",
    "train = train.drop(columns = ['ORIGIN', 'CARAVAN'])\n",
    "test = test.drop(columns = ['ORIGIN', 'CARAVAN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (5822, 85)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape: ', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(train)\n",
    "labels = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(30, 151)),\n",
    "    'learning_rate': list(np.logspace(np.log(0.01), np.log(0.2), base = np.exp(1), num = 100)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.6, 1, 10))\n",
    "}\n",
    "\n",
    "subsample_dist = list(np.linspace(0.5, 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = 5\n",
    "\n",
    "# Dataframe to hold cv results\n",
    "results = pd.DataFrame(columns = ['params', 'train_scores', 'train', 'valid_scores', 'valid', 'estimators'],\n",
    "                       index = list(range(evals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.775115\tvalid's auc: 0.764742\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttrain's auc: 0.76741\tvalid's auc: 0.767567\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.780657\tvalid's auc: 0.742874\n",
      "[400]\ttrain's auc: 0.800372\tvalid's auc: 0.754224\n",
      "[600]\ttrain's auc: 0.811003\tvalid's auc: 0.755748\n",
      "Early stopping, best iteration is:\n",
      "[586]\ttrain's auc: 0.810291\tvalid's auc: 0.756867\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.778437\tvalid's auc: 0.74782\n",
      "[400]\ttrain's auc: 0.799946\tvalid's auc: 0.757051\n",
      "Early stopping, best iteration is:\n",
      "[394]\ttrain's auc: 0.799334\tvalid's auc: 0.757856\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.784527\tvalid's auc: 0.736457\n",
      "[400]\ttrain's auc: 0.804592\tvalid's auc: 0.742194\n",
      "[600]\ttrain's auc: 0.816903\tvalid's auc: 0.743128\n",
      "[800]\ttrain's auc: 0.824552\tvalid's auc: 0.741202\n",
      "Early stopping, best iteration is:\n",
      "[691]\ttrain's auc: 0.820499\tvalid's auc: 0.743703\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.766356\tvalid's auc: 0.792491\n",
      "[400]\ttrain's auc: 0.791078\tvalid's auc: 0.795823\n",
      "[600]\ttrain's auc: 0.804039\tvalid's auc: 0.796403\n",
      "Early stopping, best iteration is:\n",
      "[500]\ttrain's auc: 0.798793\tvalid's auc: 0.798314\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.958558\tvalid's auc: 0.753705\n",
      "[400]\ttrain's auc: 0.979763\tvalid's auc: 0.762231\n",
      "[600]\ttrain's auc: 0.989989\tvalid's auc: 0.764403\n",
      "[800]\ttrain's auc: 0.992846\tvalid's auc: 0.763359\n",
      "Early stopping, best iteration is:\n",
      "[761]\ttrain's auc: 0.992345\tvalid's auc: 0.766256\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.958437\tvalid's auc: 0.723573\n",
      "[400]\ttrain's auc: 0.977414\tvalid's auc: 0.728951\n",
      "[600]\ttrain's auc: 0.987557\tvalid's auc: 0.73414\n",
      "[800]\ttrain's auc: 0.991265\tvalid's auc: 0.739965\n",
      "Early stopping, best iteration is:\n",
      "[790]\ttrain's auc: 0.991135\tvalid's auc: 0.740035\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.961028\tvalid's auc: 0.723232\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttrain's auc: 0.921091\tvalid's auc: 0.729015\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.960497\tvalid's auc: 0.710932\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttrain's auc: 0.923834\tvalid's auc: 0.715571\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.962573\tvalid's auc: 0.783832\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttrain's auc: 0.950219\tvalid's auc: 0.787448\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.825035\tvalid's auc: 0.759452\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttrain's auc: 0.776381\tvalid's auc: 0.780685\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.82467\tvalid's auc: 0.756175\n",
      "[400]\ttrain's auc: 0.838554\tvalid's auc: 0.759371\n",
      "[600]\ttrain's auc: 0.848911\tvalid's auc: 0.757161\n",
      "Early stopping, best iteration is:\n",
      "[437]\ttrain's auc: 0.841416\tvalid's auc: 0.762699\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.824349\tvalid's auc: 0.764646\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttrain's auc: 0.803931\tvalid's auc: 0.767014\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.829596\tvalid's auc: 0.750347\n",
      "[400]\ttrain's auc: 0.84401\tvalid's auc: 0.743716\n",
      "Early stopping, best iteration is:\n",
      "[202]\ttrain's auc: 0.829643\tvalid's auc: 0.750387\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.815527\tvalid's auc: 0.796325\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttrain's auc: 0.806807\tvalid's auc: 0.799771\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.8355\tvalid's auc: 0.76501\n",
      "Early stopping, best iteration is:\n",
      "[142]\ttrain's auc: 0.815916\tvalid's auc: 0.77379\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.833135\tvalid's auc: 0.745615\n",
      "[400]\ttrain's auc: 0.889121\tvalid's auc: 0.76435\n",
      "[600]\ttrain's auc: 0.921323\tvalid's auc: 0.749776\n",
      "Early stopping, best iteration is:\n",
      "[436]\ttrain's auc: 0.897083\tvalid's auc: 0.764462\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.833137\tvalid's auc: 0.753683\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttrain's auc: 0.821019\tvalid's auc: 0.75854\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.833139\tvalid's auc: 0.749064\n",
      "[400]\ttrain's auc: 0.893805\tvalid's auc: 0.738125\n",
      "Early stopping, best iteration is:\n",
      "[213]\ttrain's auc: 0.836521\tvalid's auc: 0.752465\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.829328\tvalid's auc: 0.799378\n",
      "Early stopping, best iteration is:\n",
      "[193]\ttrain's auc: 0.827635\tvalid's auc: 0.799378\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.963407\tvalid's auc: 0.762746\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttrain's auc: 0.938661\tvalid's auc: 0.772348\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.964909\tvalid's auc: 0.743706\n",
      "Early stopping, best iteration is:\n",
      "[157]\ttrain's auc: 0.947113\tvalid's auc: 0.751385\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.965909\tvalid's auc: 0.735046\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttrain's auc: 0.868026\tvalid's auc: 0.74835\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.968568\tvalid's auc: 0.711991\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttrain's auc: 0.822551\tvalid's auc: 0.747886\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.964369\tvalid's auc: 0.774629\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttrain's auc: 0.772006\tvalid's auc: 0.796875\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the specified number of evaluations\n",
    "for i in range(evals):\n",
    "    \n",
    "    k_fold = KFold(n_splits = 5)\n",
    "    \n",
    "    # Randomly sample parameters for gbm\n",
    "    params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n",
    "    \n",
    "    \n",
    "    if params['boosting_type'] == 'goss':\n",
    "        # Cannot subsample with goss\n",
    "        params['subsample'] = 1.0\n",
    "    else:\n",
    "        # Subsample supported for gdbt and dart\n",
    "        params['subsample'] = random.sample(subsample_dist, 1)[0]\n",
    "        \n",
    "        \n",
    "    # Create the model with the parameters\n",
    "    model = lgb.LGBMClassifier(class_weight = params['class_weight'], boosting_type = params['boosting_type'], \n",
    "                               num_leaves = params['num_leaves'], learning_rate = params['learning_rate'], \n",
    "                               subsample_for_bin = params['subsample_for_bin'], min_child_samples = params['min_child_samples'], \n",
    "                               reg_alpha = params['reg_alpha'], reg_lambda = params['reg_lambda'], \n",
    "                               colsample_by_tree = params['colsample_bytree'], subsample = params['subsample'], \n",
    "                               n_estimators = 10000, n_jobs = -1, objective = 'binary')\n",
    "    \n",
    "    # Empty lists for records\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    number_estimators = []\n",
    "    \n",
    "    # Split the data\n",
    "    for (train_indices, valid_indices) in k_fold.split(features):\n",
    "        \n",
    "        # Training data and validation set\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Fit the model using early stopping\n",
    "        model.fit(train_features, train_labels, eval_set = [(train_features, train_labels), (valid_features, valid_labels)],\n",
    "                  eval_metric = 'auc', eval_names = ['train', 'valid'], early_stopping_rounds = 200, verbose = 200)\n",
    "        \n",
    "        \n",
    "        valid_scores.append(model.best_score_['valid']['auc'])\n",
    "        train_scores.append(model.best_score_['train']['auc'])\n",
    "        number_estimators.append(model.best_iteration_)\n",
    "        \n",
    "    # Average the scores\n",
    "    valid = np.mean(valid_scores)\n",
    "    train = np.mean(train_scores)\n",
    "    estimators = np.mean(number_estimators)\n",
    "    \n",
    "    # Add results to next row in dataframe\n",
    "    results.loc[i, :] = [params, train_scores, train, valid_scores, valid, estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.sort_values('valid', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 0.8666666666666667,\n",
       " 'learning_rate': 0.11254789331428304,\n",
       " 'min_child_samples': 400,\n",
       " 'num_leaves': 48,\n",
       " 'reg_alpha': 0.42857142857142855,\n",
       " 'reg_lambda': 0.5714285714285714,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 60000}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Hyperparameter Optimization using Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from hyperopt.pyll.stochastic import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28d914dae48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2))}\n",
    "learning_rate_dist = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n",
    "    \n",
    "plt.hist(learning_rate_dist, bins = 10, edgecolor = 'k');\n",
    "plt.title('Learning Rate Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28d91441470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_leaves = {'num_leaves': hp.quniform('num_leaves', 30, 150, 1)}\n",
    "num_leaves_dist = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    num_leaves_dist.append(sample(num_leaves)['num_leaves'])\n",
    "    \n",
    "plt.hist(num_leaves_dist, bins = 10, edgecolor = 'k');\n",
    "plt.title('Number of Leaves Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    k_fold = KFold(n_splits = 5)\n",
    "    \n",
    "    # Retrieve the subsample if present otherwise set to 1.0\n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type\n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    \n",
    "    model = lgb.LGBMClassifier(n_estimators = 10000, objective = 'binary', n_jobs = -1, **params)\n",
    "    \n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    number_estimators = []\n",
    "    \n",
    "    for (train_indices, valid_indices) in k_fold.split(features):\n",
    "        \n",
    "        # Training data and validation set\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Fit the model using early stopping\n",
    "        model.fit(train_features, train_labels, eval_set = [(train_features, train_labels), (valid_features, valid_labels)],\n",
    "                  eval_metric = 'auc', eval_names = ['train', 'valid'], early_stopping_rounds = 200, verbose = 200)\n",
    "    \n",
    "        valid_scores.append(model.best_score_['valid']['auc'])\n",
    "        train_scores.append(model.best_score_['train']['auc'])\n",
    "        number_estimators.append(model.best_iteration_)\n",
    "        \n",
    "    # fmin needs a loss to minimize\n",
    "    valid = -1 * np.mean(valid_scores)\n",
    "    train = -1 * np.mean(train_scores)\n",
    "    \n",
    "    # average number of estimators\n",
    "    estimators = np.mean(number_estimators)\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': valid, 'train': train, 'estimators': estimators, 'status': STATUS_OK, 'params': params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss'}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_type = {'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss'}])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': {'boosting_type': 'dart', 'subsample': 0.5448263132709272}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(boosting_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': {'boosting_type': 'goss'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(boosting_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.10246628540254063}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.469495016519224}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Sampling from the space\n",
    "\n",
    "After finding the boosting type (which is in a nested dictionary), we assign the boosting type to make it a top level value. We use the dictionary get method to find the 'subsample' if it is in the dictionary (indicating the boosting type is 'gbdt' or 'dart') or set it to 1.0 otherwise (if boosting type is 'goss'). The goss boosting type cannot use bagging. \n",
    "\n",
    "This entire step is necessary because of the conditional logic used for the boosting type and subsample ratio.\n",
    "\n",
    "In addition, we can see the other variables in the dictionary. These will change every time we sample the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 0.9773709356748352,\n",
       " 'learning_rate': 0.1407872278538297,\n",
       " 'min_child_samples': 105.0,\n",
       " 'num_leaves': 79.0,\n",
       " 'reg_alpha': 0.8289180262156219,\n",
       " 'reg_lambda': 0.9396350305932608,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 0.9758127829844948,\n",
       " 'learning_rate': 0.12465302831811688,\n",
       " 'min_child_samples': 260.0,\n",
       " 'num_leaves': 46.0,\n",
       " 'reg_alpha': 0.43822106428507823,\n",
       " 'reg_lambda': 0.9935940347050338,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 140000.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.986375\tvalid's auc: 0.745473\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttrain's auc: 0.958769\tvalid's auc: 0.759309\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.986927\tvalid's auc: 0.727371\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttrain's auc: 0.971015\tvalid's auc: 0.734203\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.986819\tvalid's auc: 0.718099\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttrain's auc: 0.945166\tvalid's auc: 0.760057\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.987977\tvalid's auc: 0.675256\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttrain's auc: 0.889926\tvalid's auc: 0.7189\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.987507\tvalid's auc: 0.768098\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttrain's auc: 0.94688\tvalid's auc: 0.793174\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.816094\tvalid's auc: 0.769967\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttrain's auc: 0.794019\tvalid's auc: 0.775499\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.817211\tvalid's auc: 0.74158\n",
      "[400]\ttrain's auc: 0.862524\tvalid's auc: 0.756322\n",
      "[600]\ttrain's auc: 0.888437\tvalid's auc: 0.759371\n",
      "[800]\ttrain's auc: 0.903613\tvalid's auc: 0.756378\n",
      "Early stopping, best iteration is:\n",
      "[697]\ttrain's auc: 0.894438\tvalid's auc: 0.763469\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.817771\tvalid's auc: 0.755575\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttrain's auc: 0.808943\tvalid's auc: 0.762975\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.817852\tvalid's auc: 0.750096\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttrain's auc: 0.817777\tvalid's auc: 0.751406\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.811534\tvalid's auc: 0.798895\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttrain's auc: 0.811115\tvalid's auc: 0.799524\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.793555\tvalid's auc: 0.765793\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttrain's auc: 0.769911\tvalid's auc: 0.767736\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.796304\tvalid's auc: 0.745958\n",
      "[400]\ttrain's auc: 0.823133\tvalid's auc: 0.754825\n",
      "[600]\ttrain's auc: 0.839155\tvalid's auc: 0.755804\n",
      "Early stopping, best iteration is:\n",
      "[446]\ttrain's auc: 0.827289\tvalid's auc: 0.757301\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.796364\tvalid's auc: 0.750657\n",
      "[400]\ttrain's auc: 0.823375\tvalid's auc: 0.749416\n",
      "Early stopping, best iteration is:\n",
      "[324]\ttrain's auc: 0.814882\tvalid's auc: 0.753858\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.798636\tvalid's auc: 0.738151\n",
      "[400]\ttrain's auc: 0.825356\tvalid's auc: 0.746436\n",
      "[600]\ttrain's auc: 0.84178\tvalid's auc: 0.743637\n",
      "Early stopping, best iteration is:\n",
      "[445]\ttrain's auc: 0.829851\tvalid's auc: 0.747561\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.786668\tvalid's auc: 0.796216\n",
      "[400]\ttrain's auc: 0.817426\tvalid's auc: 0.791977\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttrain's auc: 0.786587\tvalid's auc: 0.796651\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.793873\tvalid's auc: 0.769935\n",
      "[400]\ttrain's auc: 0.839112\tvalid's auc: 0.771331\n",
      "Early stopping, best iteration is:\n",
      "[394]\ttrain's auc: 0.837141\tvalid's auc: 0.772205\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.795619\tvalid's auc: 0.741657\n",
      "[400]\ttrain's auc: 0.838025\tvalid's auc: 0.750895\n",
      "[600]\ttrain's auc: 0.874612\tvalid's auc: 0.754615\n",
      "[800]\ttrain's auc: 0.898792\tvalid's auc: 0.753483\n",
      "Early stopping, best iteration is:\n",
      "[677]\ttrain's auc: 0.885041\tvalid's auc: 0.756587\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.793343\tvalid's auc: 0.761788\n",
      "[400]\ttrain's auc: 0.839283\tvalid's auc: 0.762371\n",
      "Early stopping, best iteration is:\n",
      "[323]\ttrain's auc: 0.820748\tvalid's auc: 0.7669\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.797966\tvalid's auc: 0.743214\n",
      "[400]\ttrain's auc: 0.84184\tvalid's auc: 0.745536\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttrain's auc: 0.816635\tvalid's auc: 0.747409\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.785969\tvalid's auc: 0.787412\n",
      "[400]\ttrain's auc: 0.836992\tvalid's auc: 0.79289\n",
      "[600]\ttrain's auc: 0.873598\tvalid's auc: 0.791052\n",
      "Early stopping, best iteration is:\n",
      "[411]\ttrain's auc: 0.838732\tvalid's auc: 0.794124\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.916392\tvalid's auc: 0.75576\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttrain's auc: 0.891819\tvalid's auc: 0.769889\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.914206\tvalid's auc: 0.744168\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttrain's auc: 0.86502\tvalid's auc: 0.764336\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.916826\tvalid's auc: 0.742359\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttrain's auc: 0.802025\tvalid's auc: 0.760821\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.919552\tvalid's auc: 0.724816\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttrain's auc: 0.847585\tvalid's auc: 0.742744\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.91183\tvalid's auc: 0.787412\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttrain's auc: 0.816855\tvalid's auc: 0.801658\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 5, trials = trials, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estimators': 36.0,\n",
       "  'loss': -0.7531284893259564,\n",
       "  'params': {'boosting_type': 'goss',\n",
       "   'class_weight': 'balanced',\n",
       "   'colsample_bytree': 0.776451135695361,\n",
       "   'learning_rate': 0.0906304378048697,\n",
       "   'min_child_samples': 50,\n",
       "   'num_leaves': 140,\n",
       "   'reg_alpha': 0.12158717564944999,\n",
       "   'reg_lambda': 0.4931382166652518,\n",
       "   'subsample': 1.0,\n",
       "   'subsample_for_bin': 180000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.9423513267898096},\n",
       " {'estimators': 275.6,\n",
       "  'loss': -0.7705744625325598,\n",
       "  'params': {'boosting_type': 'dart',\n",
       "   'class_weight': None,\n",
       "   'colsample_bytree': 0.9606907171119059,\n",
       "   'learning_rate': 0.07241862479138476,\n",
       "   'min_child_samples': 330,\n",
       "   'num_leaves': 110,\n",
       "   'reg_alpha': 0.6950854939937159,\n",
       "   'reg_lambda': 0.7675299590592802,\n",
       "   'subsample': 0.6845930617820666,\n",
       "   'subsample_for_bin': 280000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.825258553577582},\n",
       " {'estimators': 295.2,\n",
       "  'loss': -0.7646214841709227,\n",
       "  'params': {'boosting_type': 'goss',\n",
       "   'class_weight': None,\n",
       "   'colsample_bytree': 0.958264836404791,\n",
       "   'learning_rate': 0.030084337358786243,\n",
       "   'min_child_samples': 270,\n",
       "   'num_leaves': 127,\n",
       "   'reg_alpha': 0.5312287116566641,\n",
       "   'reg_lambda': 0.9277762586511681,\n",
       "   'subsample': 1.0,\n",
       "   'subsample_for_bin': 60000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.8057037693012761},\n",
       " {'estimators': 419.6,\n",
       "  'loss': -0.7674449588886122,\n",
       "  'params': {'boosting_type': 'gbdt',\n",
       "   'class_weight': None,\n",
       "   'colsample_bytree': 0.6398753283559423,\n",
       "   'learning_rate': 0.012428323786953785,\n",
       "   'min_child_samples': 260,\n",
       "   'num_leaves': 88,\n",
       "   'reg_alpha': 0.8598992201575544,\n",
       "   'reg_lambda': 0.26242709789475005,\n",
       "   'subsample': 0.8492370178960422,\n",
       "   'subsample_for_bin': 240000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.8396594299419469},\n",
       " {'estimators': 66.4,\n",
       "  'loss': -0.7678895886814731,\n",
       "  'params': {'boosting_type': 'dart',\n",
       "   'class_weight': None,\n",
       "   'colsample_bytree': 0.6280078172616956,\n",
       "   'learning_rate': 0.09972694522999238,\n",
       "   'min_child_samples': 105,\n",
       "   'num_leaves': 81,\n",
       "   'reg_alpha': 0.3814007444662817,\n",
       "   'reg_lambda': 0.03618407438622695,\n",
       "   'subsample': 0.5365751881812449,\n",
       "   'subsample_for_bin': 240000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.8446608334913197}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_results = sorted(trials.results, key = lambda x: x['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'estimators': 275.6,\n",
       "  'loss': -0.7705744625325598,\n",
       "  'params': {'boosting_type': 'dart',\n",
       "   'class_weight': None,\n",
       "   'colsample_bytree': 0.9606907171119059,\n",
       "   'learning_rate': 0.07241862479138476,\n",
       "   'min_child_samples': 330,\n",
       "   'num_leaves': 110,\n",
       "   'reg_alpha': 0.6950854939937159,\n",
       "   'reg_lambda': 0.7675299590592802,\n",
       "   'subsample': 0.6845930617820666,\n",
       "   'subsample_for_bin': 280000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.825258553577582},\n",
       " {'estimators': 66.4,\n",
       "  'loss': -0.7678895886814731,\n",
       "  'params': {'boosting_type': 'dart',\n",
       "   'class_weight': None,\n",
       "   'colsample_bytree': 0.6280078172616956,\n",
       "   'learning_rate': 0.09972694522999238,\n",
       "   'min_child_samples': 105,\n",
       "   'num_leaves': 81,\n",
       "   'reg_alpha': 0.3814007444662817,\n",
       "   'reg_lambda': 0.03618407438622695,\n",
       "   'subsample': 0.5365751881812449,\n",
       "   'subsample_for_bin': 240000},\n",
       "  'status': 'ok',\n",
       "  'train': -0.8446608334913197}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('trials.json', 'w') as f:\n",
    "    f.write(json.dumps(trials_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
