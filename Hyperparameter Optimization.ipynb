{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Hyperparameter Optimization\n",
    "\n",
    "In this notebook we will explore several options for hyperparameter optimization of a machine learning algorithm. We will start with some of the basic methods such as random search, and then proceed to more sophisticated methods using Guassian Processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt as hyp\n",
    "from hyperopt import hp\n",
    "import btb\n",
    "\n",
    "from skopt.space import Real, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(objective = 'binary', n_jobs = -1, boosting_type='goss', colsample_bytree=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/application_train.csv')\n",
    "test = pd.read_csv('../input/application_test.csv')\n",
    "labels = train['TARGET']\n",
    "features, test_features = pd.get_dummies(train).align(pd.get_dummies(test), axis = 1, join = 'inner')\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels.astype(np.int32)).reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search by Hand\n",
    "\n",
    "The first method we can implement is simply random search. Each iteration, choose a random set of model hyperparameters from a search space. Empirically, random search is very effective, returning nearly as good results as grid search with a significant reduction in time spent searching. \n",
    "\n",
    "Random search can be implement in the Scikit-Learn library with the LightGBM Sklearn API. However, this does not support training with early stopping, which is the most effective method for determining the best number of iterations to use. Therefore, we will implement random search ourselves with a defined parameter grid, and using Early Stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features[:10000]\n",
    "labels = labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(30, 151)),\n",
    "    'learning_rate': list(np.logspace(np.log(0.01), np.log(0.2), base = np.exp(1), num = 100)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.6, 1, 10))\n",
    "}\n",
    "\n",
    "subsample_dist = list(np.linspace(0.5, 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = 5\n",
    "\n",
    "# Dataframe to hold cv results\n",
    "results = pd.DataFrame(columns = ['params', 'train_scores', 'train', 'valid_scores', 'valid', 'estimators'],\n",
    "                       index = list(range(evals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.993337\tvalid's auc: 0.752765\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttrain's auc: 0.845289\tvalid's auc: 0.79571\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.992936\tvalid's auc: 0.692569\n",
      "Early stopping, best iteration is:\n",
      "[95]\ttrain's auc: 0.960178\tvalid's auc: 0.719902\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.994638\tvalid's auc: 0.742551\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttrain's auc: 0.867585\tvalid's auc: 0.764146\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.994078\tvalid's auc: 0.745663\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttrain's auc: 0.908086\tvalid's auc: 0.762621\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.99347\tvalid's auc: 0.748834\n",
      "[400]\ttrain's auc: 0.999983\tvalid's auc: 0.753835\n",
      "Early stopping, best iteration is:\n",
      "[278]\ttrain's auc: 0.999315\tvalid's auc: 0.759887\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.962108\tvalid's auc: 0.791062\n",
      "Early stopping, best iteration is:\n",
      "[162]\ttrain's auc: 0.953404\tvalid's auc: 0.79265\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.962081\tvalid's auc: 0.70926\n",
      "[400]\ttrain's auc: 0.991048\tvalid's auc: 0.706754\n",
      "Early stopping, best iteration is:\n",
      "[214]\ttrain's auc: 0.965484\tvalid's auc: 0.710966\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.96067\tvalid's auc: 0.748096\n",
      "[400]\ttrain's auc: 0.989659\tvalid's auc: 0.753433\n",
      "Early stopping, best iteration is:\n",
      "[378]\ttrain's auc: 0.987751\tvalid's auc: 0.753951\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.960277\tvalid's auc: 0.743816\n",
      "[400]\ttrain's auc: 0.989671\tvalid's auc: 0.753764\n",
      "[600]\ttrain's auc: 0.998306\tvalid's auc: 0.751157\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttrain's auc: 0.995277\tvalid's auc: 0.754422\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.960376\tvalid's auc: 0.753455\n",
      "[400]\ttrain's auc: 0.989972\tvalid's auc: 0.75828\n",
      "Early stopping, best iteration is:\n",
      "[367]\ttrain's auc: 0.98718\tvalid's auc: 0.759047\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.985519\tvalid's auc: 0.784671\n",
      "[400]\ttrain's auc: 0.999909\tvalid's auc: 0.770663\n",
      "Early stopping, best iteration is:\n",
      "[215]\ttrain's auc: 0.988088\tvalid's auc: 0.784865\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.984\tvalid's auc: 0.716008\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttrain's auc: 0.975332\tvalid's auc: 0.718524\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.985633\tvalid's auc: 0.760232\n",
      "Early stopping, best iteration is:\n",
      "[140]\ttrain's auc: 0.973635\tvalid's auc: 0.763912\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.984636\tvalid's auc: 0.75305\n",
      "[400]\ttrain's auc: 0.99991\tvalid's auc: 0.755639\n",
      "[600]\ttrain's auc: 1\tvalid's auc: 0.75529\n",
      "Early stopping, best iteration is:\n",
      "[432]\ttrain's auc: 0.999974\tvalid's auc: 0.757661\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.984053\tvalid's auc: 0.746685\n",
      "[400]\ttrain's auc: 0.999963\tvalid's auc: 0.755612\n",
      "Early stopping, best iteration is:\n",
      "[365]\ttrain's auc: 0.999706\tvalid's auc: 0.758335\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.923391\tvalid's auc: 0.793799\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttrain's auc: 0.913889\tvalid's auc: 0.796423\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.923267\tvalid's auc: 0.710044\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttrain's auc: 0.833393\tvalid's auc: 0.715275\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.922304\tvalid's auc: 0.755704\n",
      "[400]\ttrain's auc: 0.965781\tvalid's auc: 0.755446\n",
      "Early stopping, best iteration is:\n",
      "[360]\ttrain's auc: 0.959058\tvalid's auc: 0.75647\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.921975\tvalid's auc: 0.754471\n",
      "[400]\ttrain's auc: 0.965197\tvalid's auc: 0.758885\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttrain's auc: 0.940084\tvalid's auc: 0.761369\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.920434\tvalid's auc: 0.751115\n",
      "[400]\ttrain's auc: 0.964076\tvalid's auc: 0.75687\n",
      "Early stopping, best iteration is:\n",
      "[347]\ttrain's auc: 0.954479\tvalid's auc: 0.758453\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.844046\tvalid's auc: 0.782783\n",
      "[400]\ttrain's auc: 0.923742\tvalid's auc: 0.780578\n",
      "[600]\ttrain's auc: 0.977439\tvalid's auc: 0.78975\n",
      "[800]\ttrain's auc: 0.99498\tvalid's auc: 0.783961\n",
      "Early stopping, best iteration is:\n",
      "[613]\ttrain's auc: 0.979711\tvalid's auc: 0.790791\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.849612\tvalid's auc: 0.716307\n",
      "Early stopping, best iteration is:\n",
      "[182]\ttrain's auc: 0.842296\tvalid's auc: 0.717829\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.847188\tvalid's auc: 0.761999\n",
      "[400]\ttrain's auc: 0.925745\tvalid's auc: 0.767283\n",
      "Early stopping, best iteration is:\n",
      "[347]\ttrain's auc: 0.904074\tvalid's auc: 0.769654\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.858694\tvalid's auc: 0.751024\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttrain's auc: 0.820734\tvalid's auc: 0.75522\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.851659\tvalid's auc: 0.731698\n",
      "[400]\ttrain's auc: 0.922403\tvalid's auc: 0.742237\n",
      "[600]\ttrain's auc: 0.974618\tvalid's auc: 0.743042\n",
      "[800]\ttrain's auc: 0.994344\tvalid's auc: 0.746813\n",
      "Early stopping, best iteration is:\n",
      "[697]\ttrain's auc: 0.987237\tvalid's auc: 0.74825\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the specified number of evaluations\n",
    "for i in range(evals):\n",
    "    \n",
    "    k_fold = KFold(n_splits = 5)\n",
    "    \n",
    "    # Randomly sample parameters for gbm\n",
    "    params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n",
    "    \n",
    "    \n",
    "    if params['boosting_type'] == 'goss':\n",
    "        # Cannot subsample with goss\n",
    "        params['subsample'] = 1.0\n",
    "    else:\n",
    "        # Subsample supported for gdbt and dart\n",
    "        params['subsample'] = random.sample(subsample_dist, 1)[0]\n",
    "        \n",
    "        \n",
    "    # Create the model with the parameters\n",
    "    model = lgb.LGBMClassifier(class_weight = params['class_weight'], boosting_type = params['boosting_type'], \n",
    "                               num_leaves = params['num_leaves'], learning_rate = params['learning_rate'], \n",
    "                               subsample_for_bin = params['subsample_for_bin'], min_child_samples = params['min_child_samples'], \n",
    "                               reg_alpha = params['reg_alpha'], reg_lambda = params['reg_lambda'], \n",
    "                               colsample_by_tree = params['colsample_bytree'], subsample = params['subsample'], \n",
    "                               n_estimators = 10000, n_jobs = -1, objective = 'binary')\n",
    "    \n",
    "    # Empty lists for records\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    number_estimators = []\n",
    "    \n",
    "    # Split the data\n",
    "    for (train_indices, valid_indices) in k_fold.split(features):\n",
    "        \n",
    "        # Training data and validation set\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Fit the model using early stopping\n",
    "        model.fit(train_features, train_labels, eval_set = [(train_features, train_labels), (valid_features, valid_labels)],\n",
    "                  eval_metric = 'auc', eval_names = ['train', 'valid'], early_stopping_rounds = 200, verbose = 200)\n",
    "        \n",
    "        \n",
    "        valid_scores.append(model.best_score_['valid']['auc'])\n",
    "        train_scores.append(model.best_score_['train']['auc'])\n",
    "        number_estimators.append(model.best_iteration_)\n",
    "        \n",
    "    # Average the scores\n",
    "    valid = np.mean(valid_scores)\n",
    "    train = np.mean(train_scores)\n",
    "    estimators = np.mean(number_estimators)\n",
    "    \n",
    "    # Add results to next row in dataframe\n",
    "    results.loc[i, :] = [params, train_scores, train, valid_scores, valid, estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.sort_values('valid', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'boosting_type': 'dart',\n",
       " 'num_leaves': 43,\n",
       " 'learning_rate': 0.15699877313755697,\n",
       " 'subsample_for_bin': 160000,\n",
       " 'min_child_samples': 115,\n",
       " 'reg_alpha': 0.8571428571428571,\n",
       " 'reg_lambda': 0.7142857142857142,\n",
       " 'colsample_bytree': 0.8222222222222222,\n",
       " 'subsample': 0.7070707070707071}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Hyperparameter Optimization using Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from hyperopt.pyll.stochastic import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2))}\n",
    "learning_rate_dist = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n",
    "    \n",
    "plt.hist(learning_rate_dist, bins = 10, edgecolor = 'k');\n",
    "plt.title('Learning Rate Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_leaves = {'num_leaves': hp.quniform('num_leaves', 30, 150, 1)}\n",
    "num_leaves_dist = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    num_leaves_dist.append(sample(num_leaves)['num_leaves'])\n",
    "    \n",
    "plt.hist(num_leaves_dist, bins = 10, edgecolor = 'k');\n",
    "plt.title('Number of Leaves Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    k_fold = KFold(n_splits = 5)\n",
    "    \n",
    "    # Retrieve the subsample if present otherwise set to 1.0\n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type\n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    \n",
    "    model = lgb.LGBMClassifier(n_estimators = 10000, objective = 'binary', n_jobs = -1, **params)\n",
    "    \n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    number_estimators = []\n",
    "    \n",
    "    for (train_indices, valid_indices) in k_fold.split(features):\n",
    "        \n",
    "        # Training data and validation set\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Fit the model using early stopping\n",
    "        model.fit(train_features, train_labels, eval_set = [(train_features, train_labels), (valid_features, valid_labels)],\n",
    "                  eval_metric = 'auc', eval_names = ['train', 'valid'], early_stopping_rounds = 200, verbose = 200)\n",
    "    \n",
    "        valid_scores.append(model.best_score_['valid']['auc'])\n",
    "        train_scores.append(model.best_score_['train']['auc'])\n",
    "        number_estimators.append(model.best_iteration_)\n",
    "        \n",
    "    # fmin needs a loss to minimize\n",
    "    valid = -1 * np.mean(valid_scores)\n",
    "    train = -1 * np.mean(train_scores)\n",
    "    \n",
    "    # average number of estimators\n",
    "    estimators = np.mean(number_estimators)\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': valid, 'train': train, 'estimators': estimators, 'status': STATUS_OK, 'params': params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss'}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_type = {'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss'}])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': {'boosting_type': 'goss'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(boosting_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': {'boosting_type': 'goss'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(boosting_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.02451170847340368}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08261993252407357}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Sampling from the space\n",
    "\n",
    "After finding the boosting type (which is in a nested dictionary), we assign the boosting type to make it a top level value. We use the dictionary get method to find the 'subsample' if it is in the dictionary (indicating the boosting type is 'gbdt' or 'dart') or set it to 1.0 otherwise (if boosting type is 'goss'). The goss boosting type cannot use bagging. \n",
    "\n",
    "This entire step is necessary because of the conditional logic used for the boosting type and subsample ratio.\n",
    "\n",
    "In addition, we can see the other variables in the dictionary. These will change every time we sample the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 0.9272910077296959,\n",
       " 'learning_rate': 0.012122763100399305,\n",
       " 'min_child_samples': 95.0,\n",
       " 'num_leaves': 101.0,\n",
       " 'reg_alpha': 0.09013896995581105,\n",
       " 'reg_lambda': 0.25964318128959485,\n",
       " 'subsample_for_bin': 120000.0,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 0.6640817620883687,\n",
       " 'learning_rate': 0.04227839096249302,\n",
       " 'min_child_samples': 100.0,\n",
       " 'num_leaves': 34.0,\n",
       " 'reg_alpha': 0.4063673530556451,\n",
       " 'reg_lambda': 0.11436338990065453,\n",
       " 'subsample_for_bin': 260000.0,\n",
       " 'subsample': 0.5603141961818652}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.994117\tvalid's auc: 0.784363\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttrain's auc: 0.992735\tvalid's auc: 0.786638\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.993607\tvalid's auc: 0.714235\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttrain's auc: 0.989305\tvalid's auc: 0.720439\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.99331\tvalid's auc: 0.748526\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttrain's auc: 0.990143\tvalid's auc: 0.752484\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.993036\tvalid's auc: 0.742581\n",
      "[400]\ttrain's auc: 0.999149\tvalid's auc: 0.749585\n",
      "[600]\ttrain's auc: 0.999947\tvalid's auc: 0.749068\n",
      "[800]\ttrain's auc: 1\tvalid's auc: 0.749103\n",
      "Early stopping, best iteration is:\n",
      "[622]\ttrain's auc: 0.999963\tvalid's auc: 0.752483\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.993326\tvalid's auc: 0.764003\n",
      "[400]\ttrain's auc: 0.999328\tvalid's auc: 0.762731\n",
      "Early stopping, best iteration is:\n",
      "[222]\ttrain's auc: 0.994652\tvalid's auc: 0.764556\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.970299\tvalid's auc: 0.729789\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttrain's auc: 0.810098\tvalid's auc: 0.790627\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.971883\tvalid's auc: 0.695243\n",
      "Early stopping, best iteration is:\n",
      "[162]\ttrain's auc: 0.961878\tvalid's auc: 0.707811\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.974182\tvalid's auc: 0.722131\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttrain's auc: 0.824415\tvalid's auc: 0.758483\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.974357\tvalid's auc: 0.715109\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttrain's auc: 0.852092\tvalid's auc: 0.747904\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.97202\tvalid's auc: 0.731236\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttrain's auc: 0.810267\tvalid's auc: 0.758318\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 1\tvalid's auc: 0.761045\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttrain's auc: 0.959532\tvalid's auc: 0.785095\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 1\tvalid's auc: 0.68705\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttrain's auc: 0.996237\tvalid's auc: 0.706872\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 1\tvalid's auc: 0.74566\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttrain's auc: 0.973202\tvalid's auc: 0.766342\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 1\tvalid's auc: 0.733319\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttrain's auc: 0.810156\tvalid's auc: 0.75534\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 1\tvalid's auc: 0.736987\n",
      "Early stopping, best iteration is:\n",
      "[160]\ttrain's auc: 1\tvalid's auc: 0.737734\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.907499\tvalid's auc: 0.785861\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttrain's auc: 0.847977\tvalid's auc: 0.79871\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.91036\tvalid's auc: 0.700411\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttrain's auc: 0.824018\tvalid's auc: 0.711148\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.90486\tvalid's auc: 0.740578\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttrain's auc: 0.86157\tvalid's auc: 0.754202\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.908154\tvalid's auc: 0.743943\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttrain's auc: 0.848657\tvalid's auc: 0.755445\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.907358\tvalid's auc: 0.757675\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttrain's auc: 0.848635\tvalid's auc: 0.761891\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.832347\tvalid's auc: 0.797011\n",
      "[400]\ttrain's auc: 0.890599\tvalid's auc: 0.786397\n",
      "Early stopping, best iteration is:\n",
      "[212]\ttrain's auc: 0.836644\tvalid's auc: 0.797925\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.842574\tvalid's auc: 0.717771\n",
      "[400]\ttrain's auc: 0.896646\tvalid's auc: 0.719835\n",
      "Early stopping, best iteration is:\n",
      "[278]\ttrain's auc: 0.867353\tvalid's auc: 0.72303\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.834565\tvalid's auc: 0.774526\n",
      "[400]\ttrain's auc: 0.892999\tvalid's auc: 0.775045\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttrain's auc: 0.870354\tvalid's auc: 0.77878\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.838472\tvalid's auc: 0.759547\n",
      "[400]\ttrain's auc: 0.893696\tvalid's auc: 0.758688\n",
      "Early stopping, best iteration is:\n",
      "[275]\ttrain's auc: 0.862414\tvalid's auc: 0.760655\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttrain's auc: 0.839185\tvalid's auc: 0.744183\n",
      "[400]\ttrain's auc: 0.892606\tvalid's auc: 0.754167\n",
      "[600]\ttrain's auc: 0.928649\tvalid's auc: 0.753573\n",
      "Early stopping, best iteration is:\n",
      "[509]\ttrain's auc: 0.913259\tvalid's auc: 0.755408\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 5, trials = trials, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -0.7553202304736557,\n",
       "  'train': -0.9933596538632701,\n",
       "  'estimators': 260.2,\n",
       "  'status': 'ok',\n",
       "  'params': {'boosting_type': 'dart',\n",
       "   'class_weight': 'balanced',\n",
       "   'colsample_bytree': 0.7325194811298903,\n",
       "   'learning_rate': 0.0322394020403845,\n",
       "   'min_child_samples': 35,\n",
       "   'num_leaves': 133,\n",
       "   'reg_alpha': 0.6040341766472112,\n",
       "   'reg_lambda': 0.9749800011842601,\n",
       "   'subsample_for_bin': 60000,\n",
       "   'subsample': 0.7393108733309419}},\n",
       " {'loss': -0.752628643339592,\n",
       "  'train': -0.851750090849617,\n",
       "  'estimators': 49.4,\n",
       "  'status': 'ok',\n",
       "  'params': {'boosting_type': 'gbdt',\n",
       "   'class_weight': 'balanced',\n",
       "   'colsample_bytree': 0.9792154501227568,\n",
       "   'learning_rate': 0.1989637872681772,\n",
       "   'min_child_samples': 400,\n",
       "   'num_leaves': 36,\n",
       "   'reg_alpha': 0.9504607597248819,\n",
       "   'reg_lambda': 0.015694998918869718,\n",
       "   'subsample_for_bin': 40000,\n",
       "   'subsample': 0.5927705664585545}},\n",
       " {'loss': -0.7502765057979331,\n",
       "  'train': -0.9478254132302046,\n",
       "  'estimators': 75.0,\n",
       "  'status': 'ok',\n",
       "  'params': {'boosting_type': 'gbdt',\n",
       "   'class_weight': None,\n",
       "   'colsample_bytree': 0.8076364340381664,\n",
       "   'learning_rate': 0.06881193077504752,\n",
       "   'min_child_samples': 35,\n",
       "   'num_leaves': 94,\n",
       "   'reg_alpha': 0.713998875650754,\n",
       "   'reg_lambda': 0.5574673465100994,\n",
       "   'subsample_for_bin': 100000,\n",
       "   'subsample': 0.6879483869461355}},\n",
       " {'loss': -0.756279342144564,\n",
       "  'train': -0.8461713716946424,\n",
       "  'estimators': 82.4,\n",
       "  'status': 'ok',\n",
       "  'params': {'boosting_type': 'gbdt',\n",
       "   'class_weight': 'balanced',\n",
       "   'colsample_bytree': 0.7619713496234854,\n",
       "   'learning_rate': 0.06898450281007874,\n",
       "   'min_child_samples': 370,\n",
       "   'num_leaves': 134,\n",
       "   'reg_alpha': 0.06031708326095664,\n",
       "   'reg_lambda': 0.6296580469258597,\n",
       "   'subsample_for_bin': 300000,\n",
       "   'subsample': 0.5360875019436323}},\n",
       " {'loss': -0.7631596069346753,\n",
       "  'train': -0.8700047665028695,\n",
       "  'estimators': 317.6,\n",
       "  'status': 'ok',\n",
       "  'params': {'boosting_type': 'goss',\n",
       "   'class_weight': None,\n",
       "   'colsample_bytree': 0.9259224457587562,\n",
       "   'learning_rate': 0.022152509734637536,\n",
       "   'min_child_samples': 150,\n",
       "   'num_leaves': 61,\n",
       "   'reg_alpha': 0.91623559266011,\n",
       "   'reg_lambda': 0.12139739021315099,\n",
       "   'subsample_for_bin': 160000,\n",
       "   'subsample': 1.0}}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_results = sorted(trials.results, key = lambda x: x['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -0.7631596069346753,\n",
       "  'train': -0.8700047665028695,\n",
       "  'estimators': 317.6,\n",
       "  'status': 'ok',\n",
       "  'params': {'boosting_type': 'goss',\n",
       "   'class_weight': None,\n",
       "   'colsample_bytree': 0.9259224457587562,\n",
       "   'learning_rate': 0.022152509734637536,\n",
       "   'min_child_samples': 150,\n",
       "   'num_leaves': 61,\n",
       "   'reg_alpha': 0.91623559266011,\n",
       "   'reg_lambda': 0.12139739021315099,\n",
       "   'subsample_for_bin': 160000,\n",
       "   'subsample': 1.0}},\n",
       " {'loss': -0.756279342144564,\n",
       "  'train': -0.8461713716946424,\n",
       "  'estimators': 82.4,\n",
       "  'status': 'ok',\n",
       "  'params': {'boosting_type': 'gbdt',\n",
       "   'class_weight': 'balanced',\n",
       "   'colsample_bytree': 0.7619713496234854,\n",
       "   'learning_rate': 0.06898450281007874,\n",
       "   'min_child_samples': 370,\n",
       "   'num_leaves': 134,\n",
       "   'reg_alpha': 0.06031708326095664,\n",
       "   'reg_lambda': 0.6296580469258597,\n",
       "   'subsample_for_bin': 300000,\n",
       "   'subsample': 0.5360875019436323}}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
