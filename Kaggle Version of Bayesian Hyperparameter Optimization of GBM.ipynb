{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: GBM Hyperparameter Optimization\n",
    "\n",
    "In this notebook we will walk through Bayesian Optimization of the hypterparameters for a Gradient Boosting Machine. We will compare the results of random search (implemented manually) with a Bayesian Method known as Tree Parzen Estimator implemented Hyperopt, an open-source Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "MAX_EVALS = 5\n",
    "CV_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For this notebook we will work with only the `application` data. The methods developed here can work on any dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (307511, 120)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>Family</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "0         Cash loans           M            N               Y             0   \n",
       "1         Cash loans           F            N               N             0   \n",
       "2    Revolving loans           M            Y               Y             0   \n",
       "3         Cash loans           F            N               Y             0   \n",
       "4         Cash loans           M            N               Y             0   \n",
       "\n",
       "   AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE NAME_TYPE_SUITE  \\\n",
       "0          202500.0    406597.5      24700.5         351000.0   Unaccompanied   \n",
       "1          270000.0   1293502.5      35698.5        1129500.0          Family   \n",
       "2           67500.0    135000.0       6750.0         135000.0   Unaccompanied   \n",
       "3          135000.0    312682.5      29686.5         297000.0   Unaccompanied   \n",
       "4          121500.0    513000.0      21865.5         513000.0   Unaccompanied   \n",
       "\n",
       "              ...             FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n",
       "0             ...                            0                0   \n",
       "1             ...                            0                0   \n",
       "2             ...                            0                0   \n",
       "3             ...                            0                0   \n",
       "4             ...                            0                0   \n",
       "\n",
       "  FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                0                0                         0.0   \n",
       "1                0                0                         0.0   \n",
       "2                0                0                         0.0   \n",
       "3                0                0                         NaN   \n",
       "4                0                0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0                        0.0                         0.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                         0.0   \n",
       "3                        NaN                         NaN   \n",
       "4                        0.0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        NaN                        NaN   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                         1.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         NaN  \n",
       "4                         0.0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data and separate into training and testing sets\n",
    "train = pd.read_csv('../input/application_train.csv')\n",
    "test = pd.read_csv('../input/application_test.csv')\n",
    "\n",
    "train_ids = train['SK_ID_CURR']\n",
    "test_ids = test['SK_ID_CURR']\n",
    "\n",
    "# Extract the labels and format properly\n",
    "train_labels = np.array(train['TARGET'].astype(np.int32)).reshape((-1,))\n",
    "\n",
    "# Drop the unneeded columns\n",
    "train = train.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "test = test.drop(columns = ['SK_ID_CURR'])\n",
    "\n",
    "print('Train shape: ', train.shape)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine Default Model\n",
    "\n",
    "We will use the LightGBM implementation of the gradient boosting machine. This is much faster than the Scikit-Learn implementation and achieves results comparable to extreme gradient boosting, XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=50,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(random_state=50)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our baseline, we will leave all of the parameters at the default values. We will evalute the performance using the 5 fold cv score on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding Categorical Variables\n",
    "\n",
    "For the default model, we will use one-hot encoding of categorical variables. The gradient boosting machine can handle categorical variables that are integer encoded, which we can look at incorporating as one of our hyperparameters over which to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  241\n"
     ]
    }
   ],
   "source": [
    "one_hot_train = pd.get_dummies(train)\n",
    "one_hot_test = pd.get_dummies(test)\n",
    "\n",
    "one_hot_train, one_hot_test = one_hot_train.align(one_hot_test, axis = 1, join = 'inner')\n",
    "one_hot_features = list(one_hot_train.columns)\n",
    "\n",
    "print('Number of features: ', one_hot_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.4min remaining:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "cv = cross_val_score(estimator = model, X = one_hot_train, y = train_labels, \n",
    "                     verbose = 2, n_jobs = -1, cv = 5, scoring = 'roc_auc')\n",
    "cv_time = timer() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model 5 fold cv AUC ROC score: 0.75697\n",
      "Baseline model eval time: 87.71 seconds.\n"
     ]
    }
   ],
   "source": [
    "print('Baseline model {} fold cv AUC ROC score: {:.5f}'.format(CV_FOLDS, np.mean(cv)))\n",
    "print('Baseline model eval time: {:.2f} seconds.'.format(cv_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding\n",
    "\n",
    "The other option we have for categorical features is label encoding. This maps each different value of a categorical feature to an integer. After we convert the values, we tell the model the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_le = train.copy()\n",
    "test_le = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  120\n"
     ]
    }
   ],
   "source": [
    "cat_features = []\n",
    "\n",
    "for i, col in enumerate(train_le):\n",
    "    if train_le[col].dtype == 'object':\n",
    "        train_le[col] = le.fit_transform(np.array(train_le[col].astype(str)).reshape((-1, )))\n",
    "        test_le[col] = le.transform(np.array(test_le[col].astype(str)).reshape((-1, )))\n",
    "        cat_features.append(i)\n",
    "        \n",
    "print('Number of features: ', train_le.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.2min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "cv = cross_val_score(estimator = model, X = train_le, y = train_labels, \n",
    "                     fit_params = {'categorical_feature': cat_features},\n",
    "                     verbose = 2, n_jobs = -1, cv = CV_FOLDS, \n",
    "                     scoring = 'roc_auc')\n",
    "cv_time = timer() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model with label ecndoing 5 fold cv AUC ROC score: 0.75584\n",
      "Baseline model with label encoding eval time: 75.11 seconds.\n"
     ]
    }
   ],
   "source": [
    "print('Baseline model with label ecndoing {} fold cv AUC ROC score: {:.5f}'.format(CV_FOLDS, np.mean(cv)))\n",
    "print('Baseline model with label encoding eval time: {:.2f} seconds.'.format(cv_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search by Hand\n",
    "\n",
    "The first method we can implement is random search. Each iteration, we choose a random set of model hyperparameters from a search space. Empirically, random search is very effective, returning nearly as good results as grid search with a significant reduction in time spent searching. \n",
    "\n",
    "Random search can be implemented in the Scikit-Learn library using `RandomizedSearchCV` because we are using the Scikit-Learn LightGBM API. \n",
    "However, this does not support training with early stopping, which is the most effective method for determining the optimal number of iterations to use. If we don't use early stopping, then the number of iterations (equivalently the number of estimators trained) becomes another hyperparameter to optimize. Therefore, we will implement random search ourselves with a defined parameter grid, using Early Stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain \n",
    "\n",
    "In random search, as in Bayesian optimization, we have a domain over which we search for the best hyperparameters. In terms of a random or grid search, this is generally known as a hyperparameter grid. First, let's look at all of the hyperparamters that need to be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the default values, we can construct the following hyperparameter grid. It's difficult to say ahead of time what choices will work best, so we will use a wide range of values for most of the hyperparameters. Some of these are discrete choices, such as `boosting_type`, while others are continuous values like `reg_alpha` and `reg_lambda` which are regularization hyperparamters between 0 and 1.0. The `subsample_dist` will be used for the `subsample` parameter but we can't just put it in the param grid because the `boosting_type=goss` does not support row subsampling. Therefore we will use an `if` statement in our evaluation to choose a subsample ratio if the boosting type is not `goss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(30, 150)),\n",
    "    'learning_rate': list(np.logspace(np.log(0.005), np.log(0.2), base = np.exp(1), num = 1000)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.6, 1, 10)),\n",
    "    'encoding': ['one_hot', 'label']\n",
    "}\n",
    "\n",
    "# Subsampling (only applicable with 'goss')\n",
    "subsample_dist = list(np.linspace(0.5, 1, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at two of the distributions, the `learning_rate` and the `num_leaves`. The learning rate is typically [represented by a logarithmic distribution](https://www.quora.com/Why-does-one-sample-the-log-space-when-searching-for-good-Hyper-Parameters-for-Machine-Learning) because it can vary over several orders of magnitude. `np.logspace` returns values evenly spaced over a log-scale (so if we take the log of the resulting values, the distribution will be uniform.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(param_grid['learning_rate'], color = 'r', edgecolor = 'k');\n",
    "plt.xlabel('Learning Rate', size = 14); plt.ylabel('Count', size = 14); plt.title('Learning Rate Distribution', size = 18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that smaller values of the learning rate are more common. The width of the domain is fairly large, so hopefully the best learning rate is somewhere in the domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(param_grid['num_leaves'], color = 'm', edgecolor = 'k')\n",
    "plt.xlabel('Learning Number of Leaves', size = 14); plt.ylabel('Count', size = 14); plt.title('Number of Leaves Distribution', size = 18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty simple domain. Let's look at how we sample a set of hyperparameters from our grid using a dictionary comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'num_leaves': 55,\n",
       " 'learning_rate': 0.051012245761693865,\n",
       " 'subsample_for_bin': 260000,\n",
       " 'min_child_samples': 35,\n",
       " 'reg_alpha': 0.9795918367346939,\n",
       " 'reg_lambda': 0.836734693877551,\n",
       " 'colsample_bytree': 0.9111111111111111,\n",
       " 'encoding': 'one_hot'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly sample parameters for gbm\n",
    "params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a `subsample` ratio if the `boosting_type` is not `goss`, we can use an if statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'num_leaves': 55,\n",
       " 'learning_rate': 0.051012245761693865,\n",
       " 'subsample_for_bin': 260000,\n",
       " 'min_child_samples': 35,\n",
       " 'reg_alpha': 0.9795918367346939,\n",
       " 'reg_lambda': 0.836734693877551,\n",
       " 'colsample_bytree': 0.9111111111111111,\n",
       " 'encoding': 'one_hot',\n",
       " 'subsample': 0.7676767676767677}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['subsample'] = random.sample(subsample_dist, 1)[0] if params['boosting_type'] != 'goss' else 1.0\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the subsample to 1.0 if boosting type is goss which is the same as not using any subsampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Random Search\n",
    "\n",
    "We have our domain and our algorithm (random selection). The other two parts we need for an optimization problem are an objective function and an object to keep track of the results. Tracking the results will be done via a `dataframe` where each row will hold one evaluation of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to hold cv results\n",
    "results = pd.DataFrame(columns = ['params', 'train', 'valid', 'estimators', 'time'],\n",
    "                       index = list(range(MAX_EVALS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function will take in the hyperparameters and return the a single real value to minimize. Based on the competition, our metric is ROC AUC. Because we can't evaluate the ROC AUC on the test set (even if we had the test answers, we could not use them because that would be cheating) we have to use a validation set.  \n",
    "\n",
    "A better approach than drawing the validation set from the training data (thereby limiting the amount of training data we have) we can use __KFOLD__ cross validation. In addition to not limiting the training data, this method should also give us a better estimate of generalization error on the test set because we will be using K validations rather than only one. For this example we will use 5-fold cross validation which means testing and training each set of model hyperparameters 5 times, each time using a different subset of the training data as the validation set. This is the same approach as we already used to evaluate the baseline models, except now we will implement this by hand in order to use Early Stopping.\n",
    "\n",
    "The objective function will return a list of metrics, the primary one of which is the validation AUC ROC. We also want to make sure to save the hyperparameters so we know which ones are optimal (or the best out of those we tried)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array for splitting in cross validation\n",
    "one_hot_features = np.array(one_hot_train)\n",
    "le_features = np.array(train_le)\n",
    "labels = train_labels[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_objective(params, n_folds = CV_FOLDS):\n",
    "    \"\"\"Random Search objective function. \n",
    "       Takes in hyperparameters and outputs a list of results to be saved.\"\"\"\n",
    "    \n",
    "    k_fold = KFold(n_splits = n_folds)\n",
    "    \n",
    "    # Handle the encoding method\n",
    "    if params['encoding'] == 'one_hot':\n",
    "        features = one_hot_features[:]\n",
    "        categorical_feature = 'auto'\n",
    "    elif params['encoding'] == 'label':\n",
    "        features= le_features[:]\n",
    "        categorical_feature = cat_features\n",
    "    \n",
    "    # Create the model with the parameters\n",
    "    model = lgb.LGBMClassifier(class_weight = params['class_weight'], boosting_type = params['boosting_type'], \n",
    "                               num_leaves = params['num_leaves'], learning_rate = params['learning_rate'], \n",
    "                               subsample_for_bin = params['subsample_for_bin'], min_child_samples = params['min_child_samples'], \n",
    "                               reg_alpha = params['reg_alpha'], reg_lambda = params['reg_lambda'], \n",
    "                               colsample_by_tree = params['colsample_bytree'], subsample = params['subsample'], \n",
    "                               n_estimators = 10000, n_jobs = -1, objective = 'binary', verbose=-1, verbose_eval = False)\n",
    "    \n",
    "    \n",
    "     # Empty lists for records\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    number_estimators = []\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    # Split the data\n",
    "    for (train_indices, valid_indices) in k_fold.split(features):\n",
    "        \n",
    "        # Training data and validation set\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Fit the model using early stopping\n",
    "        model.fit(train_features, train_labels, categorical_feature = categorical_feature,\n",
    "                  eval_set = [(train_features, train_labels), (valid_features, valid_labels)],\n",
    "                  eval_metric = 'auc', eval_names = ['train', 'valid'], \n",
    "                  early_stopping_rounds = 200, verbose = -1);\n",
    "        \n",
    "        \n",
    "        valid_scores.append(model.best_score_['valid']['auc'])\n",
    "        train_scores.append(model.best_score_['train']['auc'])\n",
    "        number_estimators.append(model.best_iteration_)\n",
    "        \n",
    "    end = timer()\n",
    "    \n",
    "    eval_time = end - start\n",
    "    \n",
    "    # Average the scores\n",
    "    valid = np.mean(valid_scores)\n",
    "    train = np.mean(train_scores)\n",
    "    estimators = np.mean(number_estimators)\n",
    "    \n",
    "    # Return a list of results\n",
    "    return [params, train, valid, estimators, eval_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write a loop to iterate through evals, each time choosing a different set of hyperparameters to evaluate. Each time through the function, the results are saved to the dataframe. \n",
    "\n",
    "The `%%capture` magic captures any outputs from running a cell in a Jupyter Notebook. This is useful because the output from a LightGBM training run cannot be suppressed. However, if we still want to see progress (but not all the progress that LightGBM shows) we can set the option `--no-display` which does not capture IPython display calls. Instead of `print`ing the information each iteration, we just call `display` with the same format. This is because print goes to `stdout` which is being `capture`d. Sorry if this is confusing, but there really does not appear to be any other method for suppressing the LightGBM output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iteration 0: 5 Fold CV AUC ROC 0.75777'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5f206b3ee9e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Evaluate the objective function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mresults_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_objective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Display the information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-e64a48e55fe4>\u001b[0m in \u001b[0;36mrandom_objective\u001b[1;34m(params, n_folds)\u001b[0m\n\u001b[0;32m     40\u001b[0m                   \u001b[0meval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                   \u001b[0meval_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                   early_stopping_rounds = 200, verbose = -1);\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    673\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    467\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1522\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1523\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1524\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1525\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "# Iterate through the specified number of evaluations\n",
    "for i in range(MAX_EVALS):\n",
    "\n",
    "    # Randomly sample parameters for gbm\n",
    "    params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n",
    "    \n",
    "    # Handle the boosting type\n",
    "    if params['boosting_type'] == 'goss':\n",
    "        # Cannot subsample with goss\n",
    "        params['subsample'] = 1.0\n",
    "    else:\n",
    "        # Subsample supported for gdbt and dart\n",
    "        params['subsample'] = random.sample(subsample_dist, 1)[0]\n",
    "        \n",
    "    # Evaluate the objective function\n",
    "    results_list = random_objective(params)\n",
    "    \n",
    "    # Display the information\n",
    "    display('Iteration {}: {} Fold CV AUC ROC {:.5f}'.format(i, CV_FOLDS, results_list[2]))\n",
    "    \n",
    "    # Add results to next row in dataframe\n",
    "    results.loc[i, :] = results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>estimators</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'class_weight': None, 'boosting_type': 'dart'...</td>\n",
       "      <td>0.884398</td>\n",
       "      <td>0.757769</td>\n",
       "      <td>496.8</td>\n",
       "      <td>1424.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params     train     valid  \\\n",
       "0  {'class_weight': None, 'boosting_type': 'dart'...  0.884398  0.757769   \n",
       "1                                                NaN       NaN       NaN   \n",
       "2                                                NaN       NaN       NaN   \n",
       "3                                                NaN       NaN       NaN   \n",
       "4                                                NaN       NaN       NaN   \n",
       "\n",
       "  estimators     time  \n",
       "0      496.8  1424.59  \n",
       "1        NaN      NaN  \n",
       "2        NaN      NaN  \n",
       "3        NaN      NaN  \n",
       "4        NaN      NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort results by best validation score\n",
    "results = results.sort_values('valid', ascending = False)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, the baseline gradient boosting model achieved a score of 0.75697 in 5-fold cv on the training data. \n",
    "\n",
    "What were the hyperparameters that returned the highest score on the objective function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': None,\n",
       " 'boosting_type': 'dart',\n",
       " 'num_leaves': 72,\n",
       " 'learning_rate': 0.09210021162737995,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'min_child_samples': 30,\n",
       " 'reg_alpha': 0.8571428571428571,\n",
       " 'reg_lambda': 0.14285714285714285,\n",
       " 'colsample_bytree': 0.7777777777777778,\n",
       " 'encoding': 'label',\n",
       " 'subsample': 0.8434343434343434}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `estimators` column holds the average number of estimators trained with early stopping over the folds. When we go to train the final model, we can train it once using this number of estimators as an estimate of the ideal value, or we can again train with early stopping using 5-fold cv, and average the predictions from each model (this also implements subsampling because each fold we are only training on a subset of the data. For example, with 5 folds, each time we are only training on 80% of the data, essentially using `subsample=0.8`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Hyperparameter Optimization using Hyperopt\n",
    "\n",
    "For Bayesian optimization in Hyperopt, we need the following four parts:\n",
    "\n",
    "1. Objective function\n",
    "2. Domain space\n",
    "3. Hyperparameter optimization algorithm\n",
    "4. History of results\n",
    "\n",
    "We already used all of these in random search, but for Hyperopt we will have to make a few changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function \n",
    "\n",
    "This objective function will still take in the parameters but it will return not a list but a dictionary. The only requirement for an objective function in Hyperopt is that it has a key in the return dictionary called `\"loss\"` to minimize and a key called `\"status\"` indicating if the evaluation was successful. \n",
    "\n",
    "If we want to keep track of the number of iterations, we can declare a global variables called `ITERATION` that is incremented every time the function is called. In addition to returning comprehensive results, every time the function is evaluated, we will write the results to a new line of a csv file. This can be useful for extremely long evaluations if we want to check on the progress (this might not be the most elegant solution, but it's better than printing to the console because our results will be saved!)\n",
    "\n",
    "The most important part of this function is that now we need to return the __negative__ of the ROC AUC. We are trying to find the best value of the objective function, and even though a higher ROC AUC is better, Hyperopt works to minimize a function and therefore the simple solution is to return the negative of the metric so that this score is driven down (meaning the positive is driven up). We could also use 1 - AUC to decrease this difference, although I don't know if it would make a difference (any help on this point is appreciated)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def objective(params, n_folds = CV_FOLDS):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    k_fold = KFold(n_splits = n_folds)\n",
    "    \n",
    "    # Retrieve the subsample if present otherwise set to 1.0\n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type\n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    \n",
    "    \n",
    "    # Handle the encoding method\n",
    "    if params['encoding'] == 'one_hot':\n",
    "        features = one_hot_features[:]\n",
    "        categorical_feature = 'auto'\n",
    "    elif params['encoding'] == 'label':\n",
    "        features= le_features[:]\n",
    "        categorical_feature = cat_features\n",
    "        \n",
    "    del params['encoding']\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**params, n_estimators = 10000, objective = 'binary', n_jobs = -1, verbose = -1)\n",
    "    \n",
    "    # Keep track of the scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    number_estimators = []\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    # KFold cross validation\n",
    "    for (train_indices, valid_indices) in k_fold.split(features):\n",
    "        \n",
    "        # Training data and validation set\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Fit the model using early stopping\n",
    "        model.fit(train_features, train_labels, categorical_feature = categorical_feature,\n",
    "                  eval_set = [(train_features, train_labels), (valid_features, valid_labels)],\n",
    "                  eval_metric = 'auc', eval_names = ['train', 'valid'], \n",
    "                  early_stopping_rounds = 200, verbose = -1)\n",
    "    \n",
    "        valid_scores.append(model.best_score_['valid']['auc'])\n",
    "        train_scores.append(model.best_score_['train']['auc'])\n",
    "        number_estimators.append(model.best_iteration_)\n",
    "        \n",
    "    end = timer()\n",
    "    run_time = end - start\n",
    "    \n",
    "    # fmin needs a loss to minimize, take average validation across folds\n",
    "    valid = -1 * np.mean(valid_scores)\n",
    "    train = -1 * np.mean(train_scores)\n",
    "    \n",
    "    # average number of estimators\n",
    "    estimators = np.mean(number_estimators)\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([valid, train, estimators, run_time, params, ITERATION])\n",
    "    \n",
    "    # Display the information\n",
    "    display('Iteration {}: {} Fold CV AUC ROC {:.5f}'.format(ITERATION, CV_FOLDS, train))\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': valid, 'train': train, 'estimators': estimators, \n",
    "            'train_time': run_time, 'status': STATUS_OK, 'params': params, 'iteration': ITERATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Space\n",
    "\n",
    "Specifying the domain (called the `space` in Hyperopt) is a little trickier than in grid search. In Hyperopt, and most other Bayesian optimization frameworks, the domian is not a strictly defined grid but rather probability distributions for each hyperparameter. Therefore, for each hyperparameter, we will use the same limits as with the grid, but instead of being defined at each point, the domain represents probabilities for each hyperparameter. This will probably become clearer in the code and the images! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will go through an example of the learning rate. Again, we are using a log-uniform space for the learning rate defined from 0.005 to 0.2 (same as with the grid.) This time, when we graph the domain, it's more accurate to see a kernel density estimate plot than a histogram (although both show distributions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the learning rate\n",
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the learning rate by sampling from the space using a Hyperopt utility. Here we plot 10000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate_dist = []\n",
    "\n",
    "# Draw 10000 samples from the learning rate domain\n",
    "for _ in range(10000):\n",
    "    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n",
    "    \n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.kdeplot(learning_rate_dist, color = 'red', linewidth = 2, shade = True);\n",
    "plt.title('Learning Rate Distribution', size = 18); plt.xlabel('Learning Rate', size = 16); plt.ylabel('Density', size = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of leaves is again a uniform distribution. Here we used `quniform` which means a discrete uniform (as opposed to continuous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Discrete uniform distribution\n",
    "num_leaves = {'num_leaves': hp.quniform('num_leaves', 30, 150, 1)}\n",
    "num_leaves_dist = []\n",
    "\n",
    "# Sample 10000 times from the number of leaves distribution\n",
    "for _ in range(10000):\n",
    "    num_leaves_dist.append(sample(num_leaves)['num_leaves'])\n",
    "    \n",
    "# kdeplot\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.kdeplot(num_leaves_dist, linewidth = 2, shade = True);\n",
    "plt.title('Number of Leaves Distribution', size = 18); plt.xlabel('Number of Leaves', size = 16); plt.ylabel('Density', size = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Domain Specification\n",
    "\n",
    "When we define a domain, each variable needs to have a label and a few parameters specifying the type and extent of the distribution. For the variables such as boosting type that are categorical, we use the `choice` variable. In Hyperopt, we can use nested conditional statements to indicate hyperparameters that depend on other hyperparameters. For example, we know that `goss` boosting type cannot use subsample, so when we set up the `boosting_type` categorical variable, we do not set a `subsample` ratio variable while we do for the other two boosting types. Let's see this with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': {'boosting_type': 'dart', 'subsample': 0.674051969004918}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boosting type domain \n",
    "boosting_type = {'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss'}])}\n",
    "\n",
    "# Draw a sample\n",
    "params = sample(boosting_type)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually set the `subsample` as a top-level key in the parameter dictionary, we can use a little conditional logic. Instead of an `if` statement, we use the Python `dict.get` method with a default value of 1.0 to set the `subsample` to whatever the value is in the `subsample` key under the `boosting_type` key, or to 1.0 if the `subsample` key is not present indicating the boosting type is `goss`. Here's the code: (This is implemented in the objective function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart', 'subsample': 0.674051969004918}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the subsample if present otherwise set to 1.0\n",
    "subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "\n",
    "# Extract the boosting type\n",
    "params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "params['subsample'] = subsample\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this is necessary because the gbm cannot use the nested dictionary so we need to set the `boosting_type` and `subsample` as top level keys.\n",
    "\n",
    "## Complete Domain\n",
    "\n",
    "With those gymnastics out of the way, we can define the entire domain space as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'encoding': hp.choice('encoding', ['one_hot', 'label']),\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss'}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Sampling from the space\n",
    "\n",
    "Let's sample from the space (using the conditional logic) to see the result of each draw. Every time we run this code, the results will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': 'balanced',\n",
       " 'colsample_bytree': 0.6023352254906976,\n",
       " 'encoding': 'one_hot',\n",
       " 'learning_rate': 0.015195760138493823,\n",
       " 'min_child_samples': 325.0,\n",
       " 'num_leaves': 79.0,\n",
       " 'reg_alpha': 0.6445840138754761,\n",
       " 'reg_lambda': 0.5824529859858351,\n",
       " 'subsample_for_bin': 60000.0,\n",
       " 'subsample': 0.7838395465788408}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample from the full space\n",
    "x = sample(space)\n",
    "\n",
    "# Conditional logic to assign top-level keys\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 0.7489692846552425,\n",
       " 'encoding': 'label',\n",
       " 'learning_rate': 0.03041155596397821,\n",
       " 'min_child_samples': 255.0,\n",
       " 'num_leaves': 53.0,\n",
       " 'reg_alpha': 0.8941312818585786,\n",
       " 'reg_lambda': 0.7475435056714671,\n",
       " 'subsample_for_bin': 60000.0,\n",
       " 'subsample': 0.9575080079517049}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Algorithm\n",
    "\n",
    "Although this is the most technical part of Bayesian optimization, defined the algorithm to use in Hyperopt is simple. We will use the Tree Parzen Estimator which is a method for constructing the surrogate function and choosing the next hyperparameters to evaluate. If we do not know now to configure the algorithm, we can use the `suggest` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result History\n",
    "\n",
    "The final part is the result history. Here, we are using two methods to make sure we capture all the results:\n",
    "\n",
    "1. A `Trials` object that stores the dictionary returned from the objective function\n",
    "2. Writing to a csv file every iteration\n",
    "\n",
    "The csv file option also lets us monitor the results of an on-going experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials\n",
    "\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to save first results\n",
    "out_file = 'gbm_trials_kaggle_round1.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'train', 'estimators', 'train_time', 'params', 'iteration'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "We have everything in place needed to run the optimization. First we declare the global variable that will be used to keep track of the number of iterations. Then, we call `fmin` passing in everything we defined above and the maximum number of iterations to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-501c9fe25a69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Run optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m best = fmin(fn = objective, space = space, algo = tpe.suggest, \n\u001b[1;32m----> 9\u001b[1;33m             max_evals = MAX_EVALS, trials = trials, verbose = 1)\n\u001b[0m",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     verbose=verbose)\n\u001b[0;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-71e541c979ca>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(params, n_folds)\u001b[0m\n\u001b[0;32m     55\u001b[0m                   \u001b[0meval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                   \u001b[0meval_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                   early_stopping_rounds = 200, verbose = -1)\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mvalid_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    673\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    467\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcallbacks_after_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[1;34m(self, feval)\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mList\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m         \"\"\"\n\u001b[1;32m-> 1649\u001b[1;33m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0m\u001b[0;32m   1650\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1648\u001b[0m         \"\"\"\n\u001b[0;32m   1649\u001b[0m         return [item for i in range_(1, self.__num_dataset)\n\u001b[1;32m-> 1650\u001b[1;33m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[1;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[0;32m   1902\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1903\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1904\u001b[1;33m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[0;32m   1905\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1906\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong length of eval results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 1\n",
    "\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = MAX_EVALS, trials = trials, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-9eecc748462a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Sort the trials with lowest loss (highest AUC) first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrials_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrials_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-9eecc748462a>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Sort the trials with lowest loss (highest AUC) first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrials_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtrials_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "trials_results = sorted(trials.results, key = lambda x: x['loss'])\n",
    "trials_results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the trial results\n",
    "with open('trials_kaggle_round1.json', 'w') as f:\n",
    "    f.write(json.dumps(trials_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep running the estimator for more iterations to get better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EVALS = 100\n",
    "\n",
    "out_file = 'gbm_trials_kaggle_round2.csv'\n",
    "\n",
    "ITERATION = 1\n",
    "\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "writer.writerow(['loss', 'train', 'estimators', 'train_time', 'params', 'iteration'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = MAX_EVALS, trials = trials, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_results = sorted(trials.results, key = lambda x: x['loss'], reverse = False)\n",
    "trials_results[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this notebook, we saw how to use Hyperopt with the Tree Parzen Estimator to optimize the hyperparameters of a gradient boosting machine. Bayesian model-based optimization is more efficient than random search, finding a better set of model hyperparameters in fewer search iterations. This is a powerful technique that we can use on any model, so long as we can define an objective function that returns a valud to minimize and a domain space over which to search. Bayesian optimization represents a significant upgrade over random search and because of the ease of use in Python, should now serve as a default choice rather than uninformed search strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
